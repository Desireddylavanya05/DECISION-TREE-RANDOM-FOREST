{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "6abaeec0-9eb8-4f20-9537-8e660070c3e1",
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Sample dataset\nnp.random.seed(42)\nX = pd.DataFrame({\n    'X1': np.random.rand(100),\n    'X2': np.random.rand(100)\n})\n# Target variable (nonlinear relationship)\ny = 3*X['X1'] + 2*X['X2'] + 4*X['X1']*X['X2'] + np.random.normal(0, 0.1, 100)\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Model with only original features\nmodel1 = LinearRegression()\nmodel1.fit(X_train, y_train)\ny_pred1 = model1.predict(X_test)\n\nprint(\"Model with original features:\")\nprint(f\"R² Score: {r2_score(y_test, y_pred1):.4f}\")\nprint(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred1)):.4f}\")\n\n# Feature engineering: Polynomial and interaction terms\npoly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\nX_poly_train = poly.fit_transform(X_train)\nX_poly_test = poly.transform(X_test)\n\n# Model with engineered features\nmodel2 = LinearRegression()\nmodel2.fit(X_poly_train, y_train)\ny_pred2 = model2.predict(X_poly_test)\n\nprint(\"\\nModel with polynomial + interaction features:\")\nprint(f\"R² Score: {r2_score(y_test, y_pred2):.4f}\")\nprint(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred2)):.4f}\")\n\n# Show feature names\nfeature_names = poly.get_feature_names_out(X.columns)\nprint(\"\\nEngineered Features:\")\nprint(feature_names)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Model with original features:\nR² Score: 0.9698\nRMSE: 0.3425\n\nModel with polynomial + interaction features:\nR² Score: 0.9981\nRMSE: 0.0855\n\nEngineered Features:\n['X1' 'X2' 'X1^2' 'X1 X2' 'X2^2']\n"
        }
      ],
      "execution_count": 1
    },
    {
      "id": "b6bd6b55-4451-47fb-ba9f-c4ea85b66ac2",
      "cell_type": "code",
      "source": "from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load dataset\niris = load_iris()\nX, y = iris.data, iris.target\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# ------------------- Decision Tree -------------------\ndt_params = {\n    'max_depth': [2, 4, 6, None],\n    'criterion': ['gini', 'entropy']\n}\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_grid = GridSearchCV(dt_model, dt_params, cv=5, scoring='accuracy')\ndt_grid.fit(X_train, y_train)\n\nprint(\"Best Decision Tree Params:\", dt_grid.best_params_)\ndt_best = dt_grid.best_estimator_\ndt_preds = dt_best.predict(X_test)\n\nprint(\"\\nDecision Tree Performance:\")\nprint(\"Accuracy:\", accuracy_score(y_test, dt_preds))\nprint(classification_report(y_test, dt_preds))\n\n# ------------------- Random Forest -------------------\nrf_params = {\n    'n_estimators': [50, 100],\n    'max_depth': [2, 4, 6, None],\n    'criterion': ['gini', 'entropy']\n}\nrf_model = RandomForestClassifier(random_state=42)\nrf_grid = GridSearchCV(rf_model, rf_params, cv=5, scoring='accuracy')\nrf_grid.fit(X_train, y_train)\n\nprint(\"\\nBest Random Forest Params:\", rf_grid.best_params_)\nrf_best = rf_grid.best_estimator_\nrf_preds = rf_best.predict(X_test)\n\nprint(\"\\nRandom Forest Performance:\")\nprint(\"Accuracy:\", accuracy_score(y_test, rf_preds))\nprint(classification_report(y_test, rf_preds))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Best Decision Tree Params: {'criterion': 'gini', 'max_depth': 4}\n\nDecision Tree Performance:\nAccuracy: 1.0\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       1.00      1.00      1.00         9\n           2       1.00      1.00      1.00        11\n\n    accuracy                           1.00        30\n   macro avg       1.00      1.00      1.00        30\nweighted avg       1.00      1.00      1.00        30\n\n\nBest Random Forest Params: {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 50}\n\nRandom Forest Performance:\nAccuracy: 1.0\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       1.00      1.00      1.00         9\n           2       1.00      1.00      1.00        11\n\n    accuracy                           1.00        30\n   macro avg       1.00      1.00      1.00        30\nweighted avg       1.00      1.00      1.00        30\n\n"
        }
      ],
      "execution_count": 2
    },
    {
      "id": "e0ea523e-5c4d-4f40-b885-e4fb2870e5ed",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}